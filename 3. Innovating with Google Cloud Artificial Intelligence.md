# Innovating with Google Cloud Artificial Intelligence

# AI and ML Fundamentals
## AI and ML defined
- Artificial Intelligence and Machine Learning are usually used interchangeably, and although they are closely realted, they differ in several ways such as scope and application.
- Artificial Intelligence: it's a set of technologies implemented in a system to mimic cognitive functions associated with human intelligence (like being able to see, understand, and respond to spoken or written language, analyze data, make recommendations,...)
- Machine Learning is a subset of AI. Let's a machine learn from data without being explicitly programmed. Relies on various models to analyze large amounts of data, learn and then make predictions and informed decisions. They improve their performance over time as they are trained or exposed to more data.
- AI is the composed by subsets: ML, Deep learning, robotics, expert systems, natural language processing
- Generative AI: type of AI that can produce new content (like text, images, audio and synthetic data). It is applied in Google Workspace to help users make summaries,...
- Generative AI APIs to help developers create customized products and services


## How AI and ML differ from data analytics and business intelligence
- Backward looking data = historical data - looks at what happened in the past; used to calculate metrics and identify trends
- ML provides a method to teach a computer how to solve problems by feeding examples of the correct answers.
- Data analytics and business intelligence identify trends from historical data, whereas AI and ML use data to make decisions for future business


## Problems that ML is suited to solve
- ML is suited to solve four common business problems:
    - Replacing or simplifying rule based systems: if all the data that's available shows which search results users clicked on per query, a ML model can be trained to predict the rank for search results
    - Automating Processes
    - Understanding unstructured data
    - Personalization (to users)


## Why ML requires high-quality data
- The accuracy of the predictions made by the ML models relies on large volumes of data that is correct and free of errors
- Data is low-quality if it's not aligned to the problem or is biased in some way
- To evaluate if we have quality data, we evaluate 6 dimensions:
    - Completeness: if all the required info is present; if the data is incomplete, then the model will not learn all the patterns that are necessary to make accurate decisions
    - Uniqueness: data should be unique; id the data set is trained with a high number of duplicates, then it will be confused and won't be able to accurately identify patterns
    - Timeliness: whether the data is up-to-date and reflects the current state of the phenomenon that's being modeled
    - Validity: the data conforms to a set of predefined standards and definitions, such as type and format. It also ensures that data is in an acceptable range
    - Accuracy: the correctness of the data. Is different from validity because validity focus on type, formant and range whether accuracy focus on form and content
    - Consistency: whether the data is uniform and doesn't contain any contraditory information


## The importance of responsible and explainable AI
- It's critical that AI is used responsably
- Google has established principles:
    - bold innovation
    - responsible development and deployment
    - collaborative progress, together
- It's important for organizations to:
    - Debug and improve ML model performance
    - Help othres understand model behavior
    - Detect and resolve bias, drift and other gaps
    - Human-interpretable explanations of ML models will help grow end-user trust and improve transparency
- Explainable AI - Google Cloud's set of tools and frameworks to help understand and interpret predictios made by ML models.



# Google Cloud's AI and ML Solutions
## BigQuery ML
- BigQuery started as a data warehouse, but over the time it has evolved to provide additional features that support the data to AI life cycle.
- BigQuery ML - democratizes the use of machine learning by empowering data analysts, but primary data warehouse users, to build and run models by using existing business intelligence tools and spreadsheets.
- Models are trained and accessed directly in BigQuery by using SQL
- reduces complexity because fewer tools are required and it also increases speed of production
- Integrates with Vertex AI


## Pre-trained APIs
- Is the fastest and lowest effort of the machine learning approaches, but is less customizable than the others.
- API's can be deployed in a virtual private cloud, on premises or in Google's public cloud regardless of the level of ML experience
- Vision API: offers pre trained ML models which use Google data to automatically detect faces, objects, text and even sentiment in images.
- Natural language API: discovers syntaxt, entities and sentiment in text and classifies text into a predefined set of categories.
- Cloud Translation API: converts text from one language to another
- Speech-to-Text API: converts audio to text for data processing
- Text-to-Speech API: converts text into high quality voice audio
- Video Intelligence API: recognizes motion and action in video.


## AutoML
- Vertex AI brings together Google Cloud services for building ML using your own training data
- AutoML and Vertex AI lets you build and train ML models by using graphical user interfaces (GUIs) without writting a line of code. -> after your data is ingested into Vertex AI, Auto ML chooses the best ML model for you by comparing different models and tuning parameters
- AutoML natural language lets you build and deploy custom ML models, to analyze documents, categorize them or assess attitudes within them.


## Custom Models
- Vertex AI is the essential platform for creating custom ML models
- Not only are models trained with your own data but they are custom built as well
- Vertex Ai provides products to help at each stage of the ML workflow:
    - gather data
    - Future engineering
    - Build models
    - Deploy and monitor models
- These fully custom ML models take the longest and require a specialized team of data scientists and engineers, however these are the most specialized to your needs and give the businesses the most differentiation and innovative results.


## TensorFlow
- Is as end to end open source platform for ML
- It has a flexible ecosystem of tools, libraries and community resources that enable researchers to innovate in ML and developers to build and deploy ML powered applications.
- TensorFlow takes advantage of the Tensor Processing Unit (TPU) wich is Google's custom developed application specific integrated circuit used to accelerate machine learning workloeads.
- TPUs act as domain specific hardware as opposed to general purpose hardware with CPUs and GPUs  


## AI Solutions
- Contact Center AI: provides models for speaking with customers and assisting human agents, increasing operational efficiency, and personalizing customer care to transform your contact center.
- Document AI: unlocks insights by extracting and classifying info from unstractered documents such as invoices, receipts, forms, letters and reports
- Discovery AI: (for retail) uses Machine Learning to select the optimal ordering of products on a retailer's e-commerce site when shoppers choose a category.
- Cloud Talent Solutions: uses AI with job search and talent acquisition capabilities and matches candidates to ideal jobs faster, and allows employers to attract and convert higher quality candidates.


## Considerations when selecting Google Cloud AI/ML solutions
- Speed: how quickly do you need to get your model to production? 
    - AI projects can typically take 3-36 months to plan and implement; 
    - Custom training usually takes the longest time because it builds the ML model from the beginning
- Differentiation:how unique is your model/how unique does it need to be?
- Expertise required
    - Organizations should consider their current team and then determine a people strategy. 
- Effort required
    - Depends on several factores such as: the complexity of the problem, the amount of data available, and the experience of the team.